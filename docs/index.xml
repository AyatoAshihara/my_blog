<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>東京の資産運用会社で働く社会人が研究に没頭するブログ</title>
    <link>/my_blog/</link>
    <description>Recent content on 東京の資産運用会社で働く社会人が研究に没頭するブログ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 27 Apr 2019 21:05:33 +0530</lastBuildDate>
    
	<atom:link href="/my_blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About me</title>
      <link>/my_blog/about/</link>
      <pubDate>Sat, 27 Apr 2019 21:05:33 +0530</pubDate>
      
      <guid>/my_blog/about/</guid>
      <description>奈良県出身の院卒2年目の25歳。関西学院大学大学院総合政策研究科修了。専攻はマクロ経済（主にDynamic Stochastic General Equilibruim model）、時系列解析やテキストマイニングにも手を出していました。現在は運用会社にて機関投資家向けのレポーティング業務に従事。広瀬すずより有村架純よりお姉ちゃんのほうがタイプ。</description>
    </item>
    
    <item>
      <title>【仕事関連】Asset Allocation ModelをRで組んでみた。</title>
      <link>/my_blog/post/post2/</link>
      <pubDate>Sun, 17 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/my_blog/post/post2/</guid>
      <description>


&lt;p&gt;今回はいつもと違って金融関連の記事を書きました。というのも社内でワークショップがあり、アセットアロケーションモデルを構築する必要が生じたからです。休日は国会図書館に籠り、先行研究を漁った結果、分散共分散行列をGARCHやARMAで推定し、最小分散ポートフォリオの性能向上を目指している論文がいくつか存在することがわかりました。今回はこれをRで実践し、推定方法によってパフォーマンスがどれほど変化するのかを実証してみたいと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>カルマンフィルタの実装（R）</title>
      <link>/my_blog/post/post3/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/my_blog/post/post3/</guid>
      <description>


&lt;p&gt;時系列解析には欠かせないカルマンフィルタ。Rでもパッケージが用意されていて非常に便利ですが、ここではいったん理解を優先し、カルマンフィルタの実装を行ってみたいと思います。ちなみに写真はカルマンフィルタの生みの親カルマンさんです（たぶん）。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>【日次GDP】ガウス回帰の実装をやってみた</title>
      <link>/my_blog/post/%E6%97%A5%E6%AC%A1gdp-%E3%82%AC%E3%82%A6%E3%82%B9%E5%9B%9E%E5%B8%B0%E3%81%AE%E5%AE%9F%E8%A3%85%E3%82%92%E3%82%84%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9F/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/my_blog/post/%E6%97%A5%E6%AC%A1gdp-%E3%82%AC%E3%82%A6%E3%82%B9%E5%9B%9E%E5%B8%B0%E3%81%AE%E5%AE%9F%E8%A3%85%E3%82%92%E3%82%84%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9F/</guid>
      <description>


&lt;p&gt;最近巷で話題になっているガウス過程。ベイズ最適化で大活躍していますが、それ以外にも利用できる点はたくさんあります。非常に柔軟でたくさんの関数を近似できる一方、尤度を評価でき、また解析解も得られることからDNNよりも使い勝手が良いと個人的には思っています。また、ベイズ推論を使用しているため、原理的に過学習しないと言う利点もあります。今回はそんなガウス過程をRで実装してみました。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>【日次GDP】BVARについて</title>
      <link>/my_blog/post/post5/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/my_blog/post/post5/</guid>
      <description>


&lt;p&gt;時系列解析の分野ではしばしばベクトル自己回帰モデル（Vector Auto Regression, VAR）が使用されます。このモデルはOLSで推定でき、手頃でありながらGrangerの因果性テストで因果関係を統計的に検定することができるなど分析者にとって強力なツールとなっています。また、VARは改良しやすいのも特徴であり、構造VARやマルコフスイッチングVAR、パネルVARなど様々な特徴を備えたVARが提案されています。今回紹介するのは、Bayesian VAR（BVAR）と呼ばれるもので、VARの仲でも予測精度の向上を目材して開発されたモデルです。GDP予測モデルとして今では有名なGDP NOWのモデルもBVARを多用しています。興味のある人は是非。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>【日次GDP】Gianonne et. al. (2008)のマルチファクターモデルで四半期GDPを予想してみた</title>
      <link>/my_blog/post/post6/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/my_blog/post/post6/</guid>
      <description>おはこんばんにちは。前回、統計ダッシュボードからAPI接続で統計データを落とすという記事を投稿しました。今回はそのデータを、Gianonne et. al. (2008)のマルチファクターモデルにかけ、四半期GDPの予測を行いたいと思います。
Gianonne et. al. (2008)版マルチファクターモデル元論文[http://dept.ku.edu/~empirics/Courses/Econ844/papers/Nowcasting%20GDP.pdf]
前回の投稿でも書きましたが、この論文はGiannoneらが2008年にパブリッシュした論文です(JME)。彼らはアメリカの経済指標を用いて四半期GDPを日次で推計し、予測指標としての有用性を示しました。指標間の連動性(colinearity)を利用して、多数ある経済指標を2つのファクターに圧縮し、そのファクターを四半期GDPにフィッティングさせることによって高い予測性を実現しています。まず、このモデルについてご紹介します。このモデルでは2段階推計を行います。まず主成分分析により経済統計を統計間の相関が0となるファクターへ変換します（
[https://datachemeng.com/principalcomponentanalysis/]
）。そして、その後の状態空間モデルでの推計で必要になるパラメータをOLS推計し、そのパラメータを使用してカルマンフィルタ＆カルマンスムーザーを回し、ファクターを推計しています。では、具体的な説明に移ります。統計データを\(x_{i,t|v_j}\)と定義します。ここで、\(i=1,...,n\)は経済統計を表し（つまり\(n\)が全統計数）、\(t=1,...,T_{iv_j}\)は統計\(i\)のサンプル期間の時点を表しています（つまり、\(T_{iv_j}\)は統計\(i\)のその時点での最新データ日付を表す）。また、\(v_j\)はある時点\(j\)（2005年など）で得られる情報集合（vintage）を表しています。統計データ\(x_{i,t|v_j}\)は以下のようにファクター\(f_{r,t}\)の線形結合で表すことができます（ここで\(r\)はファクターの数を表す）。
\[x_{i,t|v\_j} = \mu_i + \lambda_{i1}f_{1,t} + ... + \lambda_{ir}f_{r,t} + \xi_{i,t|v_j} \tag{1}\]
\(\mu\_i\)は定数項、\(\lambda\_{ir}\)はファクターローディング、\(\xi\_{i,t|v\_j}\)はホワイトノイズの誤差項を表しています。これを行列形式で書くと以下のようになります。
\[x_{t|v_j} = \mu + \Lambda F_t + \xi_{t|v_j} = \mu + \chi_t + \xi_{t|v_j} \tag{2}\]
ここで、\(x_{t|v_j} = (x_{1,t|v_j}, ..., x_{n,t|v_j} )^{\mathrm{T}}\)、\(\xi_{t|v_j}=(\xi_{1,t|v_j}, ..., \xi_{n,t|v_j})^{\mathrm{T}}\)、$ F_t = (f_{1,t}, …, f_{r,t})^{}\(であり、\)\(は各要素が\) _{ij}\(の\)nr\(行列のファクターローディングを表しています。また、\)t = F_t\(です。よって、ファクター\) F_t\(を推定するためには、データ\)x{i,t|v_j}$を以下のように基準化したうえで、分散共分散行列を計算し、その固有値問題を解けばよいという事になります。
\[\displaystyle z_{it} = \frac{1}{\hat{\sigma}_i}(x_{it} - \hat{\mu}_{it}) \tag{3}\]</description>
    </item>
    
    <item>
      <title>はじめまして</title>
      <link>/my_blog/post/post4/</link>
      <pubDate>Fri, 18 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/my_blog/post/post4/</guid>
      <description>


&lt;p&gt;どうもはじめまして。
このブログを始めるに当たってまずは自己紹介をしたいと思います。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>