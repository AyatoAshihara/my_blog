---
title: 【統計学検定】統計学1級をはじめから丁寧に（第１回 確率と確率変数）
author: Ayato Ashihara
date: '2019-09-22'
slug: post17
categories:
  - 統計
tags:
  - 統計学検定
---

<!--more-->

おはこんばんにちは。新シリーズです。統計学検定１級の内容を丁寧に学習していこうという自己満シリーズをやりたいと思います。教科書では省略されてしまう証明や式変形を丁寧に追っていきたいと思います。第１回の今回は「確率と確率変数」です。

#### 1. 事象と確率

##### 1.1 確率の計算

まず、今後使用していく用語の定義をしていきたいと思います。

・試行 - その結果が偶然によって左右される実験や観測（ex. くじを引く、サイコロを投げる）
・根源事象あるいは標本点 - 試行に対する結果
・事象 - 根源事象あるいは標本点の集合

事象には以下のような用語があります。

・全事象$\Omega$ - 結果全体の集合  
・空事象$\phi$ - 標本点を持たない空集合  
・$A$の余事象$A^c$ - $A$が起こらないという事象  
・$A$と$B$の和事象$A\cup B$ - $S$または$B$が起こるという事象  
・$A$と$B$の積事象$A\cap B$ - $A$かつ$B$が起こるという事象  
・$A$と$B$が排反 - $A\cap B=\phi$であること（$A$と$B$は同じに起こりえない）  

次に確率を定義します。統計学検定１級では測度論的確率論を用いた厳密な定義を行いません。確率は以下の３つを満たす$P(・)$と**関数**として定義されています。

1. 任意の事象$A$に対して$0\le P(A) \le 1$
2. 全事象$\Omega$に対して$P(\Omega)=1$
3. $A_1,A_2,...$が互いに排反な事象ならば$P(\displaystyle \bigcup_{i=1}^\infty A_i)=\sum_{i=1}^\infty P(A_i)$（$\sigma$加法性）

ここから以下のような定理を証明することができます。

(1)空事象$\phi$に対して$P(\phi)=0$  

$\phi$と$\Omega$は排反なので、
$$
P(\Omega) = P(\phi \cup \Omega) = P(\phi) + P(\Omega).
$$
最後の等式は$\sigma$加法性を使いました。ここから、
$$
P(\phi) = 0.
$$
となります。かなり当たり前のこと事実も定義から証明できます。空集合であって、なにも起こらない確率でないことに注意です。何も起こらないことも事象ですので。
  
(2)$A_1,A_2,...,A_n$が互いに排反な事象ならば$P(A_1\cup A_2\cup ... \cup A_n) = P(A_1)+P(A_2)+...+P(A_n)$  
  
事象$A$を$A_1,A_2,...,A_n$と$A_{n+1},A_{n+2},...$に分割します。後半を$A_{n+1},A_{n+2},...=\phi$とすると、$P(\phi)=0$なので、$\sigma$加法性より

$$
\begin{eqnarray}
P(\displaystyle \bigcup_{i=1}^\infty A_i)&=&\sum_{i=1}^\infty P(A_i) \\
&=& P(A_1)+P(A_2)+...+P(A_n) + P(A_{n+1}) + P(A_{n+2})+ ...\\
&=& P(A_1)+P(A_2)+...+P(A_n) + 0 + 0 + ...\\
&=&P(A_1\cup A_2\cup ... \cup A_n) \\
&=& P(A_1)+P(A_2)+...+P(A_n).
\end{eqnarray}
$$
無理矢理感ありますが、和事象の確率を定義できました。

(3)任意の事象$A$に対して$P(A^c)=1-P(A)$

全確率が1から導けます。
$$
1 = P(\Omega) = P(A \cup A^c) = P(A) + P(A^c)
$$
より、$P(A^c)=1-P(A)$.  

(4)任意の事象$A$と$B$に対して$P(A\cup B)=P(A)+P(B)-P(A\cap B)$（加法定理）

$$
A\cup B = (A\cap B)\cup(A\cap B^c)\cup(A^c\cap B), \\
A = (A\cap B)\cup(A\cap B^c), \\
B = (A\cap B)\cup(A^c\cap B).
$$
$A\cap B, A\cap B^c, A^c\cap B$は排反なので(2)を用いて
$$
P(A\cup B) = P(A\cap B) + P(A^c\cap B) + P(A\cap B^c),\\
P(A) = P(A\cap B) + P(A\cap B^c), \\
P(B) = P(A\cap B) + P(A^c\cap B).
$$
ここから、

$$
P(A\cap B^c) = P(A) - P(A\cap B),  \\
P(A^c\cap B) = P(B) - P(A\cap B)
$$
なので、代入すると

$$
\begin{eqnarray}
P(A\cup B) &=& P(A\cap B) + (P(A) - P(A\cap B)) + (P(B) - P(A\cap B)) \\
&=&P(A) + P(B) - P(A\cap B)

\end{eqnarray}
$$

事象$A$と$B$は排反ではないので、単純に確率を足し合わせるとかぶっている部分が出るため、その部分を引いています。

##### 1.2 統計的独立

2つの事象$A$,$B$が$P(A\cap B)=P(A)P(B)$を満たすとき、$A$と$B$は統計的独立であるといいます。ここから、余事象が独立であることも示すことができます。

(1)事象$A$と$B^c$は独立
　
$$
\begin{eqnarray}
P(A\cap B^c) &=& P(A) - P(A\cap B)  \\
&=& P(A) - P(A)P(B) \\
&=& P(A)\{1-P(B)\} \\
&=& P(A)P(B^c)
\end{eqnarray}
$$
  
(2)事象$A^c$と$B^c$は独立
  
$$
\begin{eqnarray}
P(A^c\cap B^c) &=& P(A^c)-P(A^c\cap B)\\
&=& P(A^c) - P(A^c)P(B) \\
&=&P(A^c)\{1-P(B)\} \\
&=&P(A^c)P(B^c)
\end{eqnarray}
$$
  
##### 1.3 条件付き確率
$P(A)>0$である事象$A$と事象$B$に対して、$A$が起こった条件のもとで$B$が生じる確率を$A$を与えたときの$B$の条件付き確率といいます。条件付き確率は以下で与えられます。

$$
\displaystyle P(B|A)=\frac{P(A\cap B)}{P(A)}
$$
条件付き確率には以下の性質があります。

(1)$P(・|A)$は確率の定義を満たす

$$
\displaystyle P(\phi|A)=\frac{P(\phi\cap A)}{P(A)}=\frac{P(\phi)}{P(A)} = 0\\
\displaystyle P(\Omega|A) = \frac{P(\Omega\cap A)}{P(A)} = \frac{P(A)}{P(A)} = 1 \\
$$
$B$と$C$が排反ならば、
$$
\displaystyle P(B\cup C|A)=\frac{P(A\cap B) + P(A\cap C)}{P(A)}=P(B|A)+P(C|A)
$$
  
(2)$P(B|A)=P(B)$ならば$A$と$B$は独立であり、また逆も成り立つ。
$$
\displaystyle P(B|A)=\frac{P(A\cap B)}{P(A)}=P(B)
$$
より
$$
P(A\cap B) = P(A)P(B)
$$

条件付き確率の問題ではベイズの定理を使った問題が頻出です。  
$A_1,A_2,...,A_n$が$\bigcup_{i=1}^nA_i=\Omega$を満たす互いに排反な事象ならば、任意の事象$B$に対して次が成立します。

$$
\begin{eqnarray}
\displaystyle P(A_i|B)&=&\frac{P(A_i\cap B)}{P(B)}=\frac{P(A_i \cap B)}{\sum_{i=1}^nP(A_i\cap B)}　\\
&=& \frac{P(A_i\cap B)}{P(\bigcup_{i=1}^n\{A_i\cap B\})}=\frac{P(A_i\cap B)}{P(\Omega\cap B)} \\
&=& \frac{P(B|A_i)P(A_i)}{\sum_{i=1}^nP(B|A_i)P(A_i)}
\end{eqnarray}
$$

#### 2 確率分布と母関数
##### 2.1 離散型確率変数

ある確率に基づいた試行の結果により値が定まるような変数$X$を確率変数といいます。そして、とりうる値が離散型の確率変数を離散型確率変数と呼びます。そして、

$$
f_X(x) = P(X=x)
$$
で定義される関数$f_X(・)$を$X$の確率関数といいます。$f_X(・)$のとりうる値が$x_1,x_2,...$のとき、$f_X(x)=0(x\notin\{x_1,x_2,...\})$また、ぜんかくりつが1となることより、$f_X(・)$は
$$
\displaystyle \sum_{k=1}^\infty f_X(x_k) = 1
$$
を満たします。このような確率変数のとりうる値と確率の対応関係を、その確率変数の確率分布といいます。

##### 2.2 連続型確率変数
離散型確率変数とは対照的に、とりうる値がとびとびではなく連続的な物となる確率変数を連続型確率変数といいます。連続型確率変数においては、とりうる値全てに正の確率を与えると総和が無限大になってしまうので、確率は区間に対して与えられます。$a$と$b$を定数とした時の$a\le X \le b$という事象の確率が、非負関数$f_X(・)$を用いて

$$
P(a\le X \le b) = \int_a^bf_X(x)dx
$$
で与えられるとき、この$fX(・)$を$X$の確率密度関数といいます。全確率が1であることより、$f_X(・)$は

$$
\int_{-\infty}^\infty f_X(x)dx=1
$$
を満たします。$P(X=a)=P(a\le X\le a)=0$であり、$P(a\le X\le b)=P(a<X<b)$となります。

##### 2.3 分布関数

$X$を確率変数とするとき、

$$
F_X(x)=P(X\le x)
$$
で定義される関数$F_X(・)$を$X$の累積分布関数といいます。$X$が離散型である場合は確率関数$f_X(・)$を用いて

$$
\displaystyle F_X(x) = \sum_{k:x_k\le x}f_X(x_k)
$$
となります。$X$が連続型の時は

$$
F_X(x) = \int_{-\infty}^xf_X(t)dt
$$
となります。また、これより$f_X(・)$が連続的な点で
$$
f_X(x) = \frac{d}{dx}F_X(x)
$$
が成り立つ。

##### 2.4 同時分布
複数の確率変数に対する分布を考えてみます。とりうる値が$x_1,x_2,...$と$y_1,y_2,...$である離散型確率変数$X$と$Y$に対し、

$$
f_{XY}(x,y) = P(X=x,Y=y)
$$
で定義される関数を確率関数ということができ、

$$
\displaystyle \sum_{k=1}^\infty\sum_{l=1}^\infty f_{XY}(x_k,y_l)=1
$$
となります。このような複数の確率変数の確率関数を同時確率関数といい、一部の確率変数に対する確率関数を周辺確率関数といいます。$X$と$Y$が連続の時も同様で、$a,b,c,d$を定数としたときに$a\le X\le b$かつ$c\le Y \le d$となる確率が非負の2変数関数を用いて

$$
P(a\le X \le b,c\le Y \le d)=\int_a^b\int_c^df_{XY}(x,y)dxdy
$$
で与えられるとき、$f_{XY}(・,・)$を同時確率密度関数といいます。そして、$f_X(・)$を周辺確率密度関数といいます。  
同様に、$F_{XY}(x,y)=P(X\le x,Y\le y)$で定義される$F_{XY}(・)$を同時分布関数、$F_X(・)$を周辺分布関数といいます。$X$と$Y$が連続の時、

$$
f_{XY} = \frac{\partial^2}{\partial x\partial y}F_{XY}(x,y)
$$
が成り立ちます。また、$X$と$Y$の分布をそれらの同時分布、このときの$X$の分布をその周辺分布といいます。周辺分布は同時分布から求めることができます。例えば、離散の場合は

$$
P(X=x)=P(X=x,Y\in\{y_1,y_2,...\})=\sum_{l=1}^\infty P(X=x,Y=y_l)
$$
ここから、
$$
f_X(x)=\sum_{l=1}^\infty f_{XY}(x,y_l)
$$
となります。連続の場合は
$$
P(X\le x)=P(X\le x,-\infty\le Y\le\infty)=\int_{-\infty}^x\{\int_{-\infty}^\infty f_{XY}(s,t)dt\}ds
$$
ここから
$$
f_X(x)=\int_{-\infty}^\infty f_{XY}(x,y)dy
$$
となります。

##### 2.5 確率変数の独立
離散型確率変数$X,Y$に関する事象$X\in A,Y\in B$が独立であれば

$$
\begin{eqnarray}
\sum_{k:x_k\in A}\sum_{l:y_l\in B}f_{XY}(x_k,y_l)&=&P(X\in A,Y\in B) \\
&=& P(X\in A)P(Y\in B) \\
&=& \sum_{k:x_k\in A}\sum_{l:y_l\in B}f_X(x_k)f_Y(y_l)
\end{eqnarray}
$$
となることからもわかるように、確率関数が任意の$x,y$について

$$
f_XY(x,y)=f_X(x)f_Y(y)
$$
と表せることは、$X$と$Y$に関する事象が独立であることの必要十分条件です。連続型の場合は、確率密度関数について考えればよいです。$X$と$Y$が独立であるならば、$g(・)$を適当な関数とした$g(X)$と$Y$も独立です。$g(X)$に関する事象は元をたどればXに関する事象ですので。

##### 2.6 条件付き確率
離散型確率変数$X$と$Y$に対して、$X=x$という事象を与えたときの$Y=y$という



