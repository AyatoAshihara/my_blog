---
title: 【日次GDP】Google Earth Engine APIで衛星画像データを取得し、景況感をナウキャスティングしてみる（第２回）
author: Ayato Ashiara
date: '2019-08-15'
slug: post15
categories:
  - 日次GDP
tags:
  - Earth Engine
  - Python
  - 時系列解析
image: img/portfolio/earthengine6.jpg
---



<!--more-->
<p>おはこんばんにちは。前回の記事でGoogl Earth Engineから衛星画像データを取得しました。今回はそのデータを用いて景況感のナウキャスティングをやってみます。
まず、前回取得したデータを見ましょう。</p>
<pre class="python"><code>import pandas as pd
import matplotlib.pyplot as plt
import os

os.environ[&#39;QT_QPA_PLATFORM_PLUGIN_PATH&#39;] = &#39;C:/Users/aashi/Anaconda3/Library/plugins/platforms&#39;

plt.style.use(&#39;ggplot&#39;)
plt.xkcd()</code></pre>
<pre><code>## &lt;matplotlib.pyplot.xkcd.&lt;locals&gt;.dummy_ctx object at 0x00000000273DCD30&gt;</code></pre>
<pre class="python"><code>nightjp = nightjp_csv.assign(date=lambda nightjp_csv:pd.to_datetime(nightjp_csv[&#39;system:index&#39;]))
nightjp.head()</code></pre>
<pre><code>##   system:index          sum    ...     Unnamed: 4       date
## 0     2014/1/1  881512.4572    ...            NaN 2014-01-01
## 1     2014/2/1  827345.3551    ...            NaN 2014-02-01
## 2     2014/3/1  729110.4619    ...            NaN 2014-03-01
## 3     2014/4/1  612665.8866    ...            NaN 2014-04-01
## 4     2014/5/1  661434.5027    ...            NaN 2014-05-01
## 
## [5 rows x 6 columns]</code></pre>
<pre class="python"><code>plt.plot(nightjp[&#39;date&#39;],nightjp[&#39;sum&#39;])</code></pre>
<p><img src="/my_blog/post/post15_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>かなり季節性があることがわかります。どうやら冬場に光量が大きくなる傾向になるようです。なので、季節調整をかけてみます。RではX-13ARIMA-SEATSをいつも使用していますが、pythonでの使い方がわからないので、statsmodels.apiのseasonal_decomposeを使います。冬場とそれ以外で挙動が異なるのでfreqは12にしてみました。</p>
<pre class="python"><code>import statsmodels.api as sm
nightjp = nightjp.set_index(&#39;date&#39;)
nightjp_sm = sm.tsa.seasonal_decompose(nightjp[&#39;sum&#39;],freq=12,model=&#39;multiplicative&#39;)
nightjp_sm.plot()</code></pre>
<p><img src="/my_blog/post/post15_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>季節性を除いたTrendが2016年半ばくらいから2017年下旬にかけて急激に上昇しています。おそらく、景況感とはあまり相関がなさそうな動きをしていますが、以下の記事を参考にestatからAPIで鉱工業生産指数のデータを落とし、検証してみます。</p>
<p><a href="http://sinhrks.hatenablog.com/entry/2015/12/31/222207" class="uri">http://sinhrks.hatenablog.com/entry/2015/12/31/222207</a></p>
<pre class="python"><code>import numpy as np
import japandas as jpd
import datetime 

# import IIP from estat api
dlist = jpd.DataReader(&quot;00550300&quot;, &#39;estat&#39;, appid=key)
tables = dlist[(dlist[&#39;統計表題名及び表番号&#39;].str.contains(&#39;付加価値額生産&#39;)) &amp; (dlist[&#39;提供統計名及び提供分類名&#39;].str.contains(&#39;鉱工業生産・出荷・在庫指数&#39;))]
data = jpd.DataReader(&quot;0003325360&quot;, &#39;estat&#39;, appid=key)
df = data[(data[&#39;業種別&#39;].str.contains(&#39;1000000000 鉱工業&#39;)) &amp; ~(data[&#39;統計項目A&#39;].str.contains(&#39;付加生産ウエイト&#39;))]
df = df.assign(date=lambda nightjp_csv:pd.to_datetime(df[&quot;統計項目A&quot;], format=&quot;%Y%m&quot;))
df.head()

# merge with seasonally adjusted nightlight data</code></pre>
<pre><code>##      value             業種別   統計項目A       date
## 157   94.8  1000000000 鉱工業  201301 2013-01-01
## 314   96.5  1000000000 鉱工業  201302 2013-02-01
## 471   97.7  1000000000 鉱工業  201303 2013-03-01
## 628   97.7  1000000000 鉱工業  201304 2013-04-01
## 785   99.3  1000000000 鉱工業  201305 2013-05-01</code></pre>
<pre class="python"><code>df2 = pd.merge(nightjp_sm.trend.to_frame(),df,how=&#39;left&#39;,on=&#39;date&#39;)[[&#39;date&#39;,&#39;sum&#39;,&#39;value&#39;]]

# plot
fig = plt.figure()
ax1 = fig.add_subplot(1, 1, 1)
ax1.plot(df2[&#39;date&#39;], df2[&#39;sum&#39;],&#39;C0&#39;,label=&#39;nightlight&#39;)
ax2 = ax1.twinx()
ax2.plot(df2[&#39;date&#39;], df2[&#39;value&#39;],&#39;C1&#39;,label=&#39;IIP&#39;)
h1, l1 = ax1.get_legend_handles_labels()
h2, l2 = ax2.get_legend_handles_labels()
ax1.legend(h1+h2, l1+l2, loc=&#39;lower right&#39;)
plt.show()</code></pre>
<p><img src="/my_blog/post/post15_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>予想に反し、かなり良い傾向を掴めていますね。季節調整を少し雑にやっているので、必要な情報もノイズとしてスクリーニングされた感がありますが、季節調整を真面目にやればかなり近い数値が出てくる気もします。ということで、X-13ARIMA-SEATSのpythonでの使い方をググりました。なんとstatsmodelsで動かせるようです。</p>
<pre class="python"><code>
import statsmodels as sms

# x13 
x13results = sms.tsa.x13.x13_arima_analysis(endog = nightjp[&#39;sum&#39;])
x13results.plot()

# merge with seasonally adjusted nightlight data
df3 = pd.merge(x13results.seasadj.to_frame(),df,how=&#39;left&#39;,on=&#39;date&#39;)[[&#39;date&#39;,&#39;seasadj&#39;,&#39;value&#39;]]

# plot
fig = plt.figure()
ax1 = fig.add_subplot(1, 1, 1)
ax1.plot(df3[&#39;date&#39;], df3[&#39;seasadj&#39;],&#39;C0&#39;,label=&#39;nightlight&#39;)
ax2 = ax1.twinx()
ax2.plot(df3[&#39;date&#39;], df3[&#39;value&#39;],&#39;C1&#39;,label=&#39;IIP&#39;)
h1, l1 = ax1.get_legend_handles_labels()
h2, l2 = ax2.get_legend_handles_labels()
ax1.legend(h1+h2, l1+l2, loc=&#39;lower right&#39;)
plt.show()</code></pre>
<p><img src="/my_blog/post/post15_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>そこそこ説明力高め。これは個人的には大発見です。鉱工業生産指数はGDPとの相関が高く、月次統計でもあります。ただ、生産動向統計から作成されると言うこともあり、データが公表されるタイミングは速報値が出るのが翌月末です。一方、衛星データであれば月初から推計値を計算することが可能です。まさにナウキャスティングですね。欲を言えば、日次でデータが取れれば最高なんですけどね。多分それは有料ならできるんでしょう。。。今はこれで我慢です。（いつか使える日が来るのか？）</p>
<p>単回帰もやってみます。</p>
<pre class="python"><code>
from sklearn import linear_model
clf = linear_model.LinearRegression(normalize=False)

X = df3.loc[:, [&#39;seasadj&#39;]].as_matrix()</code></pre>
<pre><code>## C:\Users\aashi\ANACON~1\python.exe:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.</code></pre>
<pre class="python"><code>Y = df3[&#39;value&#39;].as_matrix()

clf.fit(X, Y)</code></pre>
<pre><code>## LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)</code></pre>
<pre class="python"><code>print(clf.coef_,clf.intercept_,clf.score(X, Y))</code></pre>
<pre><code>## [2.24932518e-05] 85.74128984259595 0.4958790404129829</code></pre>
<pre class="python"><code>plt.scatter(X, Y)
 
plt.plot(X, clf.predict(X))</code></pre>
<p><img src="/my_blog/post/post15_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>ほぼほぼ比例の関係にありますね。決定係数は0.5でした。散布図を見ると非線形の関係にあるようにも見えるのでガウス回帰でそれも試してみます。</p>
<pre class="python"><code>
from sklearn.gaussian_process.kernels import RBF,WhiteKernel
from sklearn.gaussian_process import GaussianProcessRegressor as GPR

# kernel is RBF + white
kernel = 1*RBF()+WhiteKernel()

# estimate gp
gp = GPR(kernel,alpha=0)
gp.fit(X,Y)

# plot</code></pre>
<pre><code>## GaussianProcessRegressor(alpha=0, copy_X_train=True,
##              kernel=1**2 * RBF(length_scale=1) + WhiteKernel(noise_level=1),
##              n_restarts_optimizer=0, normalize_y=False,
##              optimizer=&#39;fmin_l_bfgs_b&#39;, random_state=None)</code></pre>
<pre class="python"><code>X1 = np.linspace(600000,850000,25000)
plt.plot(X,Y,&#39;. &#39;)
mu,std = gp.predict(X1.reshape(-1, 1),return_std=True)
plt.plot(X1,mu,&#39;g&#39;)
plt.fill_between(X1,mu-std,mu+std,alpha=0.2,color=&#39;g&#39;)
plt.show()</code></pre>
<p><img src="/my_blog/post/post15_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>770000まではほぼ直線ですが、その先で外れ値に引っ張られています。本当は750000~800000のところで二次関数のようにぐっと上昇して欲しいのですが。外れ値に引っ張られないよう、正規分布でなくt分布を仮定したt過程回帰で推計します。</p>
<p>実際の推計をする前に、理論的な話をしておきます。そもそもt分布とは正規分布の分散を増減させるパラメータを新たに与え、それがガンマ分布に従うと仮定した分布です。t過程はガウス過程と同様、有限集合<span class="math inline">\(\textbf{X}\)</span>が入力として与えられた際に、関数値ベクトル<span class="math inline">\(\textbf{f}_{TP}\)</span>の分布がその多変量t分布に従うような確率分布を言います。t過程は自由度<span class="math inline">\(v\)</span>、平均関数<span class="math inline">\(\mu\)</span>、共分散関数を要素に持つ共分散行列<span class="math inline">\(\textbf{K}\)</span>をパラメータとしています。これを<span class="math inline">\(\textbf{f}_{TP}\)</span>~<span class="math inline">\(T(v,\mu(\textbf{x}),\textbf{K}(\textbf{x},\textbf{x}&#39;))\)</span>と表します。<span class="math inline">\(T(v,\mu(\textbf{x}),\textbf{K}(\textbf{x},\textbf{x}&#39;))\)</span>は先述の通り多変量t分布です。出力である確率変数<span class="math inline">\(\textbf{y}\)</span>に対して、確率密度関数は以下のように与えられます（つまり多変量t分布の密度関数）。</p>
<p><span class="math display">\[
T(v,\mu,\textbf{K}) = \frac{\Gamma(\frac{v+n}{2})}{((v-2)\pi)^{n/2}\Gamma(\frac{v}{2})}\frac{1}{\sqrt(\det\textbf{K})}(1+\frac{(\textbf{y}-\mu)^T\textbf{K}^{-1}(\textbf{y}-\mu)}{v-2})^{-\frac{(v+n)}2}
\]</span></p>
<p>ここで、<span class="math inline">\(\Gamma\)</span>はΓ関数です。ここで、<span class="math inline">\(v\to\infty\)</span>とするとカーネルの部分が、</p>
<p><span class="math display">\[
\lim_{v\to\infty}(1+\frac{(\textbf{y}-\mu)^T\textbf{K}^{-1}(\textbf{y}-\mu)}{v-2})^{-\frac{(v+n)}2}=\exp(\frac{(\textbf{y}-\mu)^T\textbf{K}^{-1}(\textbf{y}-\mu)}{2})
\]</span></p>
<p>と正規分布に収束するので、先述の通りt分布は正規分布の一般系であることがわかります。次に、今定義したt過程を使った回帰問題について考えます。学習データ<span class="math inline">\((\textbf{x}_i,y_{i})\)</span>が手元にあるとします。t過程回帰では以下のようなモデルを考えます。</p>
<p><span class="math display">\[
y_{i} = f_{TP}(\textbf{x}_{i}) + \epsilon_{i}
\]</span>
ここで、<span class="math inline">\(f_{TP}(\textbf{x}_{i})\)</span>は基底関数による入力ベクトルの特徴量、<span class="math inline">\(\epsilon_{i}-T(v,0,\sigma^2)\)</span>は観測ノイズを表しています。また、<span class="math inline">\(\textbf{f}_{TP}=[f_{TP}(\textbf{x}_{1}),...,f_{TP}(\textbf{x}_{n})]^T\)</span>と定義し、t過程に従うとします。<span class="math inline">\(\textbf{f}_{TP}\)</span>と<span class="math inline">\(\epsilon_{i}\)</span>の分布がわかっていますから、<span class="math inline">\(\textbf{x}\)</span>が既知となった後の<span class="math inline">\(\textbf{y}\)</span>の分布を計算することができます。これはガウス過程の時と同じで、2つの独立なt分布のたたみ込みになるので、<span class="math inline">\(\textbf{y}-T(v,\mu(\textbf{x}),\textbf{K}(\textbf{x},\textbf{x}&#39;)+\sigma\textbf{I})\)</span>となります。この分布を推定するには<span class="math inline">\(\mu,\textbf{K},\sigma\)</span>を推定する必要があります。まあ、だいたい<span class="math inline">\(\mu=0,\sigma=1/100\)</span>みたいに決め打ちしてしまうことが多い気がします。重要なのは<span class="math inline">\(\textbf{K}\)</span>です。これもガウス過程と同じでカーネル関数を用いることで計算の効率化を図ります。どのカーネル関数を用いるかで推定すべきパラメータの数は変わってきますからここでは大まかな推定方法について説明したいと思います。</p>
<p>パラメータの推定方法は最尤法です。カーネル関数を<span class="math inline">\(K(\textbf{x},\textbf{x}&#39;,\beta)\)</span>と定義し、<span class="math inline">\(\beta\)</span>をパラメータとします。尤度関数は以下で与えられます。</p>
<p><span class="math display">\[
L(v,\mu,\textbf{K}(\textbf{x},\textbf{x}&#39;,\beta),\textbf{y}) = \frac{\Gamma(\frac{v+n}{2})}{((v-2)\pi)^{n/2}\Gamma(\frac{v}{2})}\frac{1}{\sqrt(\det\textbf{K}(\textbf{x},\textbf{x}&#39;,\beta))}(1+\frac{(\textbf{y}-\mu)^T\textbf{K}(\textbf{x},\textbf{x}&#39;,\beta)^{-1}(\textbf{y}-\mu)}{v-2})^{-\frac{(v+n)}2}
\]</span></p>
<p>これを最大化するような<span class="math inline">\(\beta\)</span>を最尤推定値とするのです。ここらへんもガウス過程と同じです。これで回帰の推定は完了です。とりあえずここまでをpythonで実行しましょう。</p>
