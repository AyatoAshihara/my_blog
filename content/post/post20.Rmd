---
title: LightGBMを使用して競馬結果を予想してみる
author: Ayato Ashihara
date: '2020-02-29'
slug: post20
categories:
  - 競馬
tags:
  - Python
  - 機械学習
  - 前処理
image: ''
showonlyimage: no
keywords:
  - key
  - words
topics:
  - topic 1
weight: 1
output:
  html_document
editor_options:
  chunk_output_type: console
---

<!--more-->

```{r,include=FALSE}

library(reticulate)
conda_path <- "C:\\Users\\aashi\\Anaconda3\\envs\\umanalytics"
use_condaenv(conda_path)

```

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

```{python,include=FALSE}

import os
os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = 'C:/Users/aashi/Anaconda3/envs/umanalytics/Library/plugins/platforms'


```

```{python,include=FALSE}
import sqlite3
import pandas as pd

conn = sqlite3.connect(r'C:\Users\aashi\競馬統計解析\horse_data.db')
sql = r'SELECT * FROM race_result'
df = pd.read_sql(con=conn,sql=sql)
```

おはこんばんにちは。かなり久しぶりではありますが、Pythonの勉強をかねて以前yahoo.keibaで収集した競馬のレース結果データから、レース結果を予想するモデルを作成したいと思います。

#### 1.データインポート

まず、前回Sqliteに保存したレース結果データをpandasデータフレームへ保存します。

```{python,eval=FALSE}

conn = sqlite3.connect(r'C:\hogehoge\horse_data.db')
sql = r'SELECT * FROM race_result'
df = pd.read_sql(con=conn,sql=sql)

```

データの中身を確認してみましょう。列は以下のようになっています。orderが着順となっています。

```{python}
df.columns
```

orderの中身を確認してみると、括弧（）がついている物が多く、また取消や中止、失格などが存在するため、文字型に認識されていることがわかります。ちなみに括弧（）内の順位は入線順位というやつで、他馬の走行を妨害したりして順位が降着させられたことを意味します（http://www.jra.go.jp/judge/）。

```{python}
df.loc[:,'order'].unique()
```

まずここを修正しましょう。括弧を除去してint型に型変更し、入線順位は新たな列「arriving order」として追加します。

```{python}
df['arriving order'] = df[df.order.str.contains(r'\d*\(\d*\)',regex=True)]['order'].replace(r'\d+\(',r'',regex=True).replace(r'\)',r'',regex=True).astype('float64')
df['arriving order'].unique()
```

```{python}
df['order'] = df['order'].replace(r'\(\d+\)',r'',regex=True)
df = df[lambda df: ~df.order.str.contains(r'(取消|中止|除外|失格)',regex=True)]
df['order'] = df['order'].astype('float64')
df['order'].unique()
```

きれいなfloat型に処理することができました。では、次にラスト3Fのタイムの前処理に移ります。前走のラスト3Fのタイムを予測に使用します。

```{python}
import numpy as np
df['race_date'] =  pd.to_datetime('1970/1/1') + pd.to_timedelta(df['race_date'], unit='days') # convert serial to datetime
df['last_3F'] = df['last_3F'].replace(r'character(0)',np.nan,regex=False).astype('float64')
df['last_3F'] = df.groupby('horse_name')['last_3F'].shift(-1)
```

前走のレースと順位、追加順位もデータセットへ含めましょう。

```{python}
df['prerace'] = df.groupby('horse_name')['race_name'].shift(-1)
df['preorder'] = df.groupby('horse_name')['order'].shift(-1)
df['prepassing'] = df.groupby('horse_name')['passing_rank'].shift(-1)
```

出走時点で獲得している累積賞金額も追加します。

```{python}
df['preprize'] = df.groupby('horse_name')['prize'].shift(-1)
df['preprize'] = df['preprize'].fillna(0)
df['margin'] = df.groupby('horse_name')['margin'].shift(-1)
```

その他、欠損値やデータ型の修正、カテゴリデータのラベルエンコーディングです。

```{python}
df['horse_weight'] = df['horse_weight'].astype('float64')
df['margin'] = df['margin'].replace(r'character(0)',np.nan,regex=False)
df['horse_age'] = df['horse_age'].astype('float64')
df['horse_weight_change'] = df['horse_weight_change'].astype('float64')
df['jockey_weight'] = df['jockey_weight'].astype('float64')
df['race_distance'] = df['race_distance'].replace(r'm',r'',regex=True).astype('float64')
df['race_turn'] = df['race_turn'].replace(r'character(0)',np.nan,regex=False)
df.loc[df['order']!=1,'order'] = 0

df['race_turn'] = df['race_turn'].fillna('missing')
df['colour'] = df['colour'].fillna('missing')
df['prepassing'] = df['prepassing'].fillna('missing')
df['prerace'] = df['prerace'].fillna('missing')
df['father'] = df['father'].fillna('missing')
df['mother'] = df['mother'].fillna('missing')

from sklearn import preprocessing
cat_list = ['trainer', 'horse_name', 'horse_sex', 'brinker', 'jockey', 'race_course', 'race_name', 'type', 'race_turn', 'race_condition', 'race_weather', 'colour', 'father', 'mother', 'prerace', 'prepassing']
for column in cat_list:
    target_column = df[column]
    le = preprocessing.LabelEncoder()
    le.fit(target_column)
    label_encoded_column = le.transform(target_column)
    df[column] = pd.Series(label_encoded_column).astype('category')

```


```{python,eval=FALSE}
import pandas_profiling as pdq
profile = pdq.ProfileReport(df)
profile
```

ではlightgbmで予測モデルを作ってみます。optunaのlightgbmを使用して、ハイパーパラメータチューニングを行い、学習したモデルを用いて計算したテストデータの予測値と実績値のconfusion matrixならびに正解率を算出します。

```{python,include=FALSE}
import optuna.integration.lightgbm as lgb
from sklearn.model_selection import train_test_split

y = df['order']
x = df.drop(['order','passing_rank','time','odds','popularity','owner','farm','locality','horse_birthday','http','prize','race_date','margin'],axis=1)

X_train, X_test, y_train, y_test = train_test_split(x, y)
X_train, x_val, y_train, y_val = train_test_split(X_train, y_train)

lgb_train = lgb.Dataset(X_train, y_train)
lgb_eval = lgb.Dataset(x_val, y_val)
lgb_test = lgb.Dataset(X_test, y_test, reference=lgb_train)

lgbm_params = {
        'objective': 'binary',
        'metric': 'auc'
    }

best_params, history = {}, []
model = lgb.train(lgbm_params, lgb_train, categorical_feature = cat_list,valid_sets = lgb_eval, num_boost_round=100,early_stopping_rounds=20,best_params=best_params,tuning_history=history, verbose_eval=False)
best_params

y_pred = np.vectorize(lambda x: 1 if x > 0.49 else 0)(model.predict(X_test, num_iteration=model.best_iteration))

```

```{python,eval=FALSE}
import optuna.integration.lightgbm as lgb
from sklearn.model_selection import train_test_split

y = df['order']
x = df.drop(['order','passing_rank','time','odds','popularity','owner','farm','locality','horse_birthday','http','prize','race_date','margin'],axis=1)

X_train, X_test, y_train, y_test = train_test_split(x, y)
X_train, x_val, y_train, y_val = train_test_split(X_train, y_train)

lgb_train = lgb.Dataset(X_train, y_train)
lgb_eval = lgb.Dataset(x_val, y_val)
lgb_test = lgb.Dataset(X_test, y_test, reference=lgb_train)

lgbm_params = {
        'objective': 'binary',
        'metric': 'auc'
    }

best_params, history = {}, []
model = lgb.train(lgbm_params, lgb_train, categorical_feature = cat_list,valid_sets = lgb_eval, num_boost_round=100,early_stopping_rounds=20,best_params=best_params,tuning_history=history, verbose_eval=False)
best_params

y_pred = np.vectorize(lambda x: 1 if x > 0.49 else 0)(model.predict(X_test, num_iteration=model.best_iteration))

```

可視化パートです。

```{python}
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score
import matplotlib.pyplot as plt
import seaborn as sns

confusion_matrix(y_test, y_pred)
labels = sorted(list(set(y_test)))
#ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred),labels).plot()

accuracy_score(y_test, y_pred)
precision_score(y_test, y_pred)

```

accuracy_score（予測制度）が90%を超え、precision_Score（陽=1着と予想したデータの正解率）もいい感じです。
shapで要因分解もしてみましょう。

```{python}
import shap

shap.initjs()
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

shap.summary_plot(shap_values, X_test)
shap.summary_plot(shap_values[1], X_test)

shap.dependence_plot(ind="preprize", shap_values=shap_values[1], features=X_test)
shap.dependence_plot(ind="preorder", shap_values=shap_values[1], features=X_test)

```

