---
title: 【日次GDP】Google Earth Engine APIで衛星画像データを取得し、景況感をナウキャスティングしてみる
author: Ayato Ashihara
date: '2019-07-16'
slug: post14
categories:
  - 日次GDP
tags:
  - R
  - 前処理
  - Earth Engine
output:
  html_document:
    toc: true
    toc_depth: 3
---

<!--more-->

皆さんおはこんばんにちわ。前回、GPLVMモデルを用いたGDP予測モデルを構築しました。ただ、ナウキャスティングというからにはオルタナティブデータを用いた解析を行いたいところではあります。ふと、以下の記事を見つけました。

https://jp.reuters.com/article/gdp-u-tokyo-idJPKBN15M0NH

こちらは東京大学の渡辺努先生が人工衛星画像を用いてGDP予測モデルを開発したというものです。記事には

>米国の海洋大気庁が運営する気象衛星「スオミＮＰＰ」が日本上空を通過する毎日午前１時３０分時点の画像を購入し、縦、横７２０メートル四方のマス目ごとの明るさを計測する。同じ明るさでも、農地、商業用地、工業用地など土地の用途によって経済活動の大きさが異なるため、国土地理院の土地利用調査を参照。土地の用途と、明るさが示す経済活動の相関を弾き出し、この結果を考慮した上で、明るさから経済活動の大きさを試算する。
>（中略）衛星画像のように誰もが入手可能な公表データであれば、政府、民間の区別なく分析が可能であるため、渡辺氏はこれを「統計の民主化」と呼び、世界的な潮流になると予想している。

と書かれており、衛星写真を用いた分析に興味を惹かれました。 衛星写真って誰でも利用可能か？というところですが、GoogleがEarth Engineというサービスを提供していることがわかりました
。

![](\img\portfolio\earthengine3.jpg)

https://earthengine.google.com/

>（拙訳）Google Earth Engineは、数ペタバイトの衛星画像群と地理空間データセットを惑星規模の解析機能と組み合わせ、科学者、研究者、開発者が変化を検出し、傾向を射影し、地球の変容を定量化することを可能にします。


研究・教育・非営利目的ならば、なんと**無料**で衛星写真データを解析することができます。具体的に何ができるのかは以下の動画を見てください。

<iframe src="//www.youtube.com/embed/gKGOeTFHnKY" width="100%" height="50" seamless frameborder="0" allowfullscreen></iframe>

今回はそんなEath Engineのpython APIを用いて衛星画像データを取得し、解析していきたいと思います。

### 1. Earth Engineを使うための事前準備


### 2. Python APIを用いた衛星画像データの取得

```{r,include=FALSE}

library(reticulate)
conda_path <- "C:\\Users\\aashi\\Anaconda3"
use_condaenv(conda_path)

```

```{python}

import ee
from dateutil.parser import parse

ee.Initialize()

# get Japan geometory as FeatureCollection from fusion table
japan = ee.FeatureCollection('ft:1tdSwUL7MVpOauSgRzqVTOwdfy17KDbw-1d9omPw').filter(ee.Filter.eq('Country', 'Japan'))

# get night-light data from earth engine from 2014-01-01 to 2019-01-01
dataset = ee.ImageCollection('NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG').filter(ee.Filter.date('2014-01-01','2019-01-01')).select('avg_rad')

# initialize output box
time0 = dataset.first().get('system:time_start');
first = dataset.first().reduceRegions(reducer=ee.Reducer.sum(),collection=japan,scale=1000).set('time_start', time0)

# define reduceRegions function for iteration
def myfunc(image,first):
  added = image.reduceRegions(reducer=ee.Reducer.sum(),collection=japan,scale=1000).set('time_start', image.get('system:time_start'))
  return ee.FeatureCollection(first).merge(added)

# implement iteration
nightjp = dataset.filter(ee.Filter.date('2014-02-01','2019-01-01')).iterate(myfunc,first)

# get url to download
ee.FeatureCollection(nightjp).getDownloadURL(filetype='csv',selectors=ee.FeatureCollection(nightjp).first().propertyNames().getInfo())


```

